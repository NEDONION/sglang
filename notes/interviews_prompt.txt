你现在是一名资深 AI Infra / LLM Infra / 系统架构工程师，对以下内容有深度掌握：
- SGLang 全部源码与系统架构（executor、runtime、KV cache、parallelism、IR、调度等）
- vLLM、TensorRT-LLM、Ray Serve、DeepSpeed-Inference 等推理框架
- CUDA、NCCL、分布式系统、内存管理、流水线并行、计算图优化
- 大规模 LLM 推理系统的工程实现与面试标准

============================================================
任务目标
============================================================
请生成一套 **SGLang 源码级 + AI Infra 方向的面试题**，难度从中级到专家级，适用于 AI Infra / LLM Infra / Model Serving 岗位面试。

面试题必须覆盖（但不限于）：
1. SGLang 架构：Executor、Graph IR、Runtime、Tokenizer、KV Cache 管理
2. SGLang 与 vLLM 的核心差异（block table、调度策略、prefill/decoding 流程）
3. SGLang 的 ComputeGraph / IR 优化机制
4. SGLang 的异步推理、并行执行模型
5. SGLang 的 streaming token 推理原理
6. SGLang 的 Operator 实现、CUDA Kernel、Memory Layout
7. SGLang 的 compile-and-run 执行模型
8. SGLang 在多 GPU / 分布式推理中的扩展方式
9. AI Infra 必备底层：CUDA、NCCL、Pinned Memory、Zero-copy、RPC、调度策略等

============================================================
输出格式
============================================================
请按如下格式输出：

## Level 1（基础理解）
- 问题 1：……
- 问题 2：……

## Level 2（源码走查）
- 问题 3：……
- 问题 4：……

## Level 3（系统设计 + 原理深入）
- 问题 5：……
- 问题 6：……

## Level 4（高级 AI Infra / 架构 + 源码细节）
- 问题 7：……
- 问题 8：……

## Level 5（专家级：面向架构与优化）
- 问题 9：……
- 问题 10：……

============================================================
附加要求
============================================================
1. 每个问题必须指向 SGLang 源码的具体部分（路径或模块）。
2. 难度必须梯度式提升，从概念到架构再到源码级别。
3. 最后请生成一套“标准答案”，包括：
   - 原理解释
   - 源码位置
   - 与 vLLM 的关键差异
   - 工程 trade-offs

============================================================

请立即生成问题与标准答案。
